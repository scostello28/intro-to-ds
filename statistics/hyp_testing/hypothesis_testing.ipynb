{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Payphone Fills\n",
    "\n",
    "Past data have shown that if the payphones at the airport are emptied every 14 days, the coin collectors will be 70% full on the average. The phone company tries to schedule the collection visits at 70% full because money is lost if the phones get full and unusable, but visiting the phones too frequently is also an expense. The company keeps data on fill amounts during collection, in case they need to increase or decrease collection frequency. During the last visit, suppose that 5 phones were 50%, 40%, 70%, 75%, and 45% full, respectively. Do you think the frequency of visits needs to be changed, or is this just chance variation? (95% confidence is fine.)\n",
    "Hint: Note that an action will be made (increase or decrease visits) if the average fill shifts away from the mean (70%)  in either direction. State your hypotheses based on this fact.\n",
    "\n",
    "Hint 2: You’ll need a p-value calculator to find the p-value: https://www.graphpad.com/quickcalcs/pvalue1.cfm \n",
    "\n",
    "\n",
    "Thoughts:\n",
    "\n",
    "Sample **standard deviation** (or just sddev) is essentially how off from the mean each observation is on average. It is a measurement of a distributions spread. If the std dev is low then the distribution is tight around the mean reflecting more certainty. On the other hand, if it is a large number it reflects the opposite, that the sampled data is less certain (i.e. nore variance). Std dev is scaled to the metric in question, meaning that if were looking at salary information then the scale will be in the tens or hundreds of thousands, while if age is the metric then the scale is much less. That is said to illustrate the knowledge needed to use this metric when undertsanding data. \n",
    "\n",
    "It is useful to remove the scale of std dev by converting it to a statistic. With large values on n (I think ~25) a **Z-score** can be used. Z-score essentially converts std_dev to a dimensionless value--how many std devs is each data point from the mean--and can allow for estimating a normal distribution. This will change the distribution to be centered on 0 but remain with the same shape. The Z-score is related to the Z-statistic which can illustrate how far from the known mean the new smaplled data is. The Z-statistic then corresponds directly to p-value depending on the type of test used-one or two tailed. \n",
    "\n",
    "In the examples below we use the **t-statistic** which, like the Z-statistic estiamtes a normal. distribution just with less data. With less data the t-distribution is wider than the Z-distribution since there is less certainty. \n",
    "\n",
    "**P-value** is a meausre of the probabulity that the change seen in the sample data is due to random chance and does not represent the true popolation. THis is useful when measureing change to understand if the differences we are seeing in our new sample is real and worth taking action from. We want to know. for sure that the changes we are making based on these new observations are in fact going to lead us to our desired destination and prevent us from chasing our each time a new set of information comes our way.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_std_dev(array):\n",
    "    sample_mu = array.mean()\n",
    "    n = len(array)\n",
    "    return np.sqrt(np.sum((array - sample_mu) ** 2 )/ (n-1))\n",
    "\n",
    "def t_statistic(samples_array, mu):\n",
    "    sample_mu = samples_array.mean()\n",
    "    s = sample_std_dev(samples_array)\n",
    "    n = len(samples_array)\n",
    "    return (sample_mu - mu) / (s / np.sqrt(n))\n",
    "\n",
    "def p_value_from_t_statistic(t_stat, dof, tails=1):\n",
    "    if tails == 1:\n",
    "        if t_stat > 0:\n",
    "            return 1 - stats.t.cdf(t_stat, dof)\n",
    "        else:\n",
    "            return stats.t.cdf(t_stat, dof)\n",
    "    else: \n",
    "        if t_stat > 0:\n",
    "            return (1 - stats.t.cdf(t_stat, dof)) * 2\n",
    "        else:\n",
    "            return stats.t.cdf(t_stat, dof) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given fill data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fills = np.array([50, 40, 70, 75, 45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compute t as shown below:\n",
    "\n",
    "$$ t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bar = fills.mean()\n",
    "x_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\(\\mu\\\\) is our average fill that we are testing our hypothesis against. In this case meaning that with all of our historical data the average fullness of each payphone is 70% after 14 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 70 # Null Hypothesis H0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample standard deviation needs degress of freedom \\\\(n-1\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.5724\n"
     ]
    }
   ],
   "source": [
    "# With formula\n",
    "s = sample_std_dev(fills)\n",
    "print(\"{:.4f}\".format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.5724\n"
     ]
    }
   ],
   "source": [
    "# With numpy\n",
    "s = fills.std(ddof=1)\n",
    "print(\"{:.4f}\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n is our number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With len function\n",
    "n = len(fills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With numpy shape attribute\n",
    "fills.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 5\n"
     ]
    }
   ],
   "source": [
    "n = fills.shape[0]\n",
    "print(\"n: {}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_satatistic: -2.0103\n"
     ]
    }
   ],
   "source": [
    "t_stat = t_statistic(fills, mu)\n",
    "print(\"t_satatistic: {:.4f}\".format(t_stat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two tailed signifcance value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.025\n"
     ]
    }
   ],
   "source": [
    "alpha = (1.0 - 0.95) / 2\n",
    "print('alpha: {:.3f}'.format(alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, we are investigating whether we should increase OR decrease the inspection rate we need to test in whether a change is real either direction. This is known as a two-tailed test. To account for both directions we need to split the 5% chance of the data different not sue to random chance to both sides of the distribution. So with a required 95% confidence the calculated p-value must be < 0.025 for us to accept the change. \n",
    "\n",
    "Accepting the change means to reject the Null Hypothesis that the data does not provide evidence for us to change from the status quo. Any evidence that would get us to take action and make a change must be definative--to whatever confidence level we choose. In  other words, it needs to be hard to prove somthing wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.1148\n"
     ]
    }
   ],
   "source": [
    "# p-value from scipy stats or can find form link above\n",
    "p = p_value_from_t_statistic(t_stat, n-1, 2)\n",
    "print('p-value: {:.4f}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -2.0103\n",
      "p-value: 0.1148\n"
     ]
    }
   ],
   "source": [
    "# p-value form scipy stats\n",
    "t_stat, p_val = stats.ttest_1samp(a=fills, popmean=mu)\n",
    "print(\"t-statistic: {:.4f}\".format(t_stat))\n",
    "print(\"p-value: {:.4f}\".format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we reject \\\\(H_0\\\\)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p <= alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot reject the null hypothesis because our data is more likey to occur given the null hypothesis is true than our significance level of 0.025.  In other words, our data cannot prove, with significance, that the average payphone fill after 14 days is not 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains\n",
    "\n",
    "People in DC constantly complain that the metro consistently runs an average of 10 minutes late. You actually think it’s less than this, so you gather data for ten different trains at a specific location in DC. The following is your data in minutes of lateness: [4, 12, 6, 2, 1, 6, 7, 3, 16, 0]. Based on your data, are the people in DC correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = 10\n",
    "# h1 -> < 10 therefore left-tailed (one-tailed) test\n",
    "\n",
    "# One-tailed significance value\n",
    "C = 0.95\n",
    "alpha = 1 - C\n",
    "\n",
    "train_samples = np.array([4, 12, 6, 2, 1, 6, 7, 3, 16, 0])\n",
    "n = len(train_samples)\n",
    "sample_mean = train_samples.mean()\n",
    "s = sample_std_dev(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_satatistic: -2.7129\n"
     ]
    }
   ],
   "source": [
    "t_stat = t_statistic(train_samples, h0)\n",
    "print(\"t_satatistic: {:.4f}\".format(t_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.0239\n"
     ]
    }
   ],
   "source": [
    "p = p_value_from_t_statistic(t_stat, n-1, tails=2)\n",
    "print('p-value: {:.4f}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -2.7129\n",
      "p-value: 0.0239\n"
     ]
    }
   ],
   "source": [
    "# p-value form scipy stats\n",
    "t_stat, p_val = stats.ttest_1samp(a=train_samples, popmean=h0)\n",
    "print(\"t-statistic: {:.4f}\".format(t_stat))\n",
    "print(\"p-value: {:.4f}\".format(p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p <= alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reject the null hypothesis because our p-value is less that out significance level (alpha).  In other words, there is less than a 5% chance that we would observe the recorded data if trains we 10 minutes late on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
